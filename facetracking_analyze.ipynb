{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<H1>FaceShape Data</H1>\n",
    "Exploratory analysis of single dyad."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Paths to log files\n",
    "LOG_SUBJ1 = r\"prepped_data/facetracking/8_1.csv\"\n",
    "LOG_SUBJ2 = r\"prepped_data/facetracking/8_2.csv\"\n",
    "\n",
    "# Logging intervalls in seconds\n",
    "LOGGING_RATE = 0.1\n",
    "\n",
    "# Save images to png if true\n",
    "SAVE_IMG = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read Data\n",
    "The FaceShape data is a time series of the weightings of all eye and lip shapes the\n",
    "HTC Facial Tracker recorded."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Read data\n",
    "df_subj1 = pd.read_csv(LOG_SUBJ1)\n",
    "df_subj2 = pd.read_csv(LOG_SUBJ2)\n",
    "\n",
    "# Convert time to datetime objects\n",
    "df_subj1[\"Time\"] = df_subj1[\"Time\"].apply(pd.to_datetime)\n",
    "df_subj2[\"Time\"] = df_subj2[\"Time\"].apply(pd.to_datetime)\n",
    "\n",
    "# Time as index\n",
    "df_subj1 = df_subj1.set_index(\"Time\")\n",
    "df_subj2 = df_subj2.set_index(\"Time\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'prepped_data/facetracking/8_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_14920/2649753312.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# Read data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mdf_subj1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mLOG_SUBJ1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mdf_subj2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mLOG_SUBJ2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    480\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    481\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 482\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    483\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    484\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 811\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    812\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    813\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1038\u001B[0m             )\n\u001B[0;32m   1039\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \"\"\"\n\u001B[1;32m--> 222\u001B[1;33m         self.handles = get_handle(\n\u001B[0m\u001B[0;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m             \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    700\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    701\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 702\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    703\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    704\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'prepped_data/facetracking/8_1.csv'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "First comparison of data from both subjects."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, sharey=True, figsize=(10,5))\n",
    "\n",
    "prefix = \"Mouth_Smile\"\n",
    "fs1 = (df_subj1.iloc[:, df_subj1.columns.str.startswith(prefix)].sum(axis=1))\n",
    "fs2 = (df_subj2.iloc[:, df_subj2.columns.str.startswith(prefix)].sum(axis=1))\n",
    "\n",
    "fig.suptitle('FaceShape Signals')\n",
    "axs[0].plot(fs1)\n",
    "axs[1].plot(fs2)\n",
    "\n",
    "fig.tight_layout()\n",
    "if SAVE_IMG: plt.savefig(\"out/img/signals.png\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Analysis\n",
    "We now do a Cross-Correlation analysis across both these signals. Pandas does not offer\n",
    "a native method to this. But there is a simple implementation using Pandas .corr()\n",
    "method from\n",
    "https://towardsdatascience.com/computing-cross-correlation-between-geophysical-time-series-488642be7bf0\n",
    "\n",
    "As the interpersonal synchrony can change over time, we slice the Dataframe into 1 minute\n",
    "slices to assess the change of pacing in mimicry by the change of lags and extent\n",
    "of maximal correlation.\n",
    "The following function slices the dataframes into equal parts. We want one minute\n",
    "of data for each slice. We compute the seconds per slice and divide by the rate\n",
    "of the time series.\n",
    "\n",
    "### Cross-Correlation between two signals\n",
    "Using this function, we can compute the Cross-Correlation of two signals at different time\n",
    "lags."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def crosscorr(datax, datay, lag=0):\n",
    "    \"\"\"\n",
    "    Lag-N cross correlation.Shifted data filled with NaNs\n",
    "    :param lag: default 0\n",
    "    :param datax, datay: pandas.Series objects of equal length\n",
    "    :return: Float indicating cross-correlation\n",
    "    \"\"\"\n",
    "\n",
    "    return datax.corr(datay.shift(lag))\n",
    "\n",
    "prefix = \"Mouth_Smile\"\n",
    "\n",
    "signal1 = (df_subj1.iloc[:, df_subj1.columns.str.startswith(prefix)].apply(sum, axis=1)\n",
    "                / len(df_subj1.columns.str.startswith(prefix)))\n",
    "signal2 = (df_subj2.iloc[:, df_subj2.columns.str.startswith(prefix)].apply(sum, axis=1)\n",
    "                / len(df_subj2.columns.str.startswith(prefix)))\n",
    "\n",
    "signal1 = signal1.reset_index(drop=True)\n",
    "signal2 = signal2.reset_index(drop=True)\n",
    "\n",
    "# Compute Cross-Correlation at different time lags\n",
    "lags = np.arange(-75, 75, 1)\n",
    "rs = np.nan_to_num([crosscorr(signal1, signal2, lag) for lag in lags])\n",
    "\n",
    "# Calculate maximum correlation and maximizing time lag\n",
    "max_rs, min_rs = np.abs(np.max(rs)), np.abs(np.min(rs))\n",
    "if np.abs(max_rs) >= np.abs(min_rs):\n",
    "    corr_val = max_rs\n",
    "    corr_lag = lags[np.argmax(rs)]\n",
    "else:\n",
    "    corr_val = min_rs\n",
    "    corr_lag = lags[np.argmin(rs)]\n",
    "\n",
    "# Visualization of Cross-Correlation\n",
    "fig, ax = plt.subplots(2, 1, figsize=(18, 9))\n",
    "ax[0].plot(signal1, lw=0.7, c='b')\n",
    "ax[0].plot(signal2, lw=0.7, c='r')\n",
    "ax[1].plot(lags, rs, c='k', label='Cross-Correlation')\n",
    "ax[1].axvline(x=corr_lag, c='r', lw=1, ls='--', label='Max. correlation')\n",
    "ax[1].xticks(corr_lag/10)\n",
    "ax[1].legend(fontsize=12)\n",
    "\n",
    "if SAVE_IMG: plt.savefig('out/img/cross_corr_example.png')\n",
    "plt.show()\n",
    "\n",
    "md(f\"By shifting the second signal by {corr_lag} ms we get a maximum \"\n",
    "   f\"correlation of r={corr_val} between both signals.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Windowed Time Lagged Cross-Correlation\n",
    "\n",
    "https://towardsdatascience.com/four-ways-to-quantify-synchrony-between-time-series-data-b99136c4a9c9"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "lag_seconds = 5\n",
    "lag_steps = LOGGING_RATE  # At least LOGGING_RATE\n",
    "window_size = 5\n",
    "\n",
    "def vectorized_crosscorr(df):\n",
    "    s1 = df.iloc[:, 0]\n",
    "    s2 = df.iloc[:, 1]\n",
    "    rs = [crosscorr(s1,s2, lag) for lag in range(-int(lag_seconds/lag_steps),int(lag_seconds/lag_steps+1))]\n",
    "    rs = np.nan_to_num(rs)\n",
    "    return rs\n",
    "\n",
    "def fisher_z(corr_r):\n",
    "    \"\"\" Compute Fisher's Z transformation\n",
    "    for given correlation value.\n",
    "    :param corr_r: correlation value\n",
    "    :return: Z-value\n",
    "    \"\"\"\n",
    "    if corr_r == 1:\n",
    "        return 0\n",
    "    return np.arctanh(corr_r)\n",
    "\n",
    "def v_fisher_z(corr_r):\n",
    "    \"\"\" Compute Fisher's Z transformation\n",
    "    for given correlation value.\n",
    "    :param corr_r: correlation value\n",
    "    :return: Z-value\n",
    "    \"\"\"\n",
    "    if corr_r == 1:\n",
    "        return 0\n",
    "    return np.arctanh(corr_r)\n",
    "\n",
    "def windowed_crosscorr(ts1, ts2, plot=False):\n",
    "    \"\"\" Cross-correlate time series over time windows \"\"\"\n",
    "    df_comb = ts1.to_frame()\n",
    "    df_comb[ts2.name + '_subj2'] = ts2\n",
    "\n",
    "    # Resample in <window_size> intervals\n",
    "    # resampler = df_comb.resample(f\"{window_size}s\")\n",
    "    resampler = df_comb.groupby(pd.Grouper(freq=f\"{window_size}s\"))\n",
    "    rss = resampler.apply(vectorized_crosscorr)\n",
    "    rss = pd.DataFrame.from_dict(dict(zip(rss.index, rss.values)), orient='index')\n",
    "\n",
    "    if plot:\n",
    "        f,ax = plt.subplots(figsize=(10,5))\n",
    "        sns.heatmap(rss,cmap='RdBu_r',ax=ax)\n",
    "        ax.set(title=f'Windowed Time Lagged Cross Correlation',xlim=[0,100],\n",
    "               xlabel='Time-lag of cross-correlation',ylabel='Time Frame')\n",
    "        x = 2 * lag_seconds/LOGGING_RATE\n",
    "        ax.set_xticks([0, int(x/4), int(x/2), int(3*x/4), int(x)])\n",
    "        ax.set_xticklabels([-int(x/2),-int(x/4), 0, int(x/4), int(x/2)])\n",
    "        if SAVE_IMG: plt.savefig(\"out/img/windowed_time_lagged_crosscorr.png\")\n",
    "\n",
    "    sync = rss.apply(lambda row: [fisher_z(r) for r in row]).max(axis=1).abs().mean()\n",
    "    mean_lag = rss.apply(lambda row: [fisher_z(r) for r in row]).idxmax(axis=1).mean()\n",
    "\n",
    "    return sync, mean_lag\n",
    "\n",
    "# df_sync = pd.DataFrame(columns=[\"feature\", \"synchrony\"])\n",
    "# for i in range(0, len(df_subj1.columns)):\n",
    "#     sync, mean_lag = windowed_crosscorr(df_subj1.iloc[:, i], df_subj2.iloc[:, i])\n",
    "#     df_sync = df_sync.append({\"feature\": df_subj1.columns[i], \"synchrony\": sync, \"lag\": mean_lag}, ignore_index=True)\n",
    "#\n",
    "# df_sync = df_sync.set_index(\"feature\")\n",
    "prefix_cols = df_subj1.columns.str.startswith(prefix)\n",
    "windowed_crosscorr(df_subj1[\"Mouth_LowerRight_Down\"], df_subj2[\"Mouth_LowerRight_Down\"], plot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rolling Window Time Lagged Cross-Correlation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if SAVE_IMG: plt.savefig('out/img/rolling_window_cross_corr.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Cross-Correlation between <i>all</i> signals</h3>\n",
    "We can compute the Cross-Correlation of the signals of all FaceShapes.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Activate by removing md\n",
    "\n",
    "lags = np.arange(-200, 200, 1)\n",
    "\n",
    "corr_lags = []\n",
    "corr_vals = []\n",
    "\n",
    "for i, col in enumerate(df_subj1.columns):\n",
    "    # Compute Cross-Correlation at different time lags\n",
    "    rs = np.nan_to_num(\n",
    "        [crosscorr(df_subj1[col], df_subj2[col], lag) for lag in lags])\n",
    "\n",
    "    # Calculate maximum correlation and maximizing time lag\n",
    "    max_rs, min_rs = np.abs(np.max(rs)), np.abs(np.min(rs))\n",
    "    if np.abs(max_rs) >= np.abs(min_rs):\n",
    "        corr_val = max_rs\n",
    "        corr_lag = lags[np.argmax(rs)]\n",
    "    else:\n",
    "        corr_val = min_rs\n",
    "        corr_lag = lags[np.argmin(rs)]\n",
    "\n",
    "    corr_lags.append(corr_lag)\n",
    "    corr_vals.append(corr_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "By looking at the distribution of time lags of all Cross-Correlations, we can assess the\n",
    "synchrony of all facial expressions between both subjects. We use Fisher's Z transformation\n",
    "to standardize the correlation values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_corr = pd.DataFrame(\n",
    "    data={\"Correlation Value\": corr_vals, \"Lag\": corr_lags},\n",
    "    columns = ['Correlation Value', 'Lag'])\n",
    "\n",
    "df_corr[\"Correlation Value\"] = df_corr[\"Correlation Value\"].apply(lambda x: fisher_z(abs(x)))\n",
    "df_corr[\"FaceShape\"] = pd.Series(df_subj1.columns)\n",
    "print(df_corr.sort_values(by=[\"Correlation Value\"], ascending=False))\n",
    "\n",
    "ax = df_corr['Correlation Value'].plot.hist(bins=20)\n",
    "print(\"Synchrony as the average standardized correlation value:\",\n",
    "    sum(df_corr['Correlation Value']) / len(df_corr['Correlation Value']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_lags = pd.DataFrame(\n",
    "    corr_lags,\n",
    "    columns = ['Correlation Lag Values'])\n",
    "\n",
    "# Standardize by Fisher's Z\n",
    "ax = df_lags.plot.hist(bins=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Highest correlations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_corr.sort_values(\"Correlation Value\", ascending=False).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}